{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarveshPatil99/Adversarial-Robustness-Enhancement/blob/main/TML_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2fQjAR5h8fg"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEInq2G4h-5w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Change the current working directory\n",
        "new_directory = \"/content/drive/MyDrive/TML_Project/data/\"\n",
        "os.chdir(new_directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "select_a_dataset = \"StyleGAN3 10000\" # @param [\"StyleGAN3 5000\", \"StyleGAN3 10000\", \"StyleGAN2 5000\"]\n",
        "\n",
        "if select_a_dataset == \"StyleGAN3 5000\":\n",
        "  !gdown https://drive.google.com/uc?id=1-BTtMGzH8925FtIu20KbkfmmSz3LNTer\n",
        "  !unzip -q original_dataset.zip\n",
        "elif select_a_dataset == \"StyleGAN3 10000\":\n",
        "  !gdown https://drive.google.com/uc?id=18MZZwgKjTGlB2Y4Esw_lRIvbpOaANbnh\n",
        "  !unzip -q original_dataset_stylegan3_10000.zip\n",
        "elif select_a_dataset == \"StyleGAN2 5000\":\n",
        "  !gdown https://drive.google.com/uc?id=1ZBxnHMArN2-HAdViUFKarKxuXVk4sREk\n",
        "  !unzip -q original_dataset_stylegan2_5000.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "ugSuaZ2fQfm7",
        "outputId": "a0800c2d-87a7-4a53-eebf-7f20b236b82c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18MZZwgKjTGlB2Y4Esw_lRIvbpOaANbnh\n",
            "To: /content/original_dataset_stylegan3_10000.zip\n",
            "100% 2.12G/2.12G [00:23<00:00, 91.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the device to train on\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transforms for the training, validation, and testing sets\n",
        "transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the datasets with ImageFolder\n",
        "data_dir = 'original'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), transforms[x])\n",
        "                  for x in ['train', 'val', 'test']}\n",
        "\n",
        "# Define a dataloader\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
        "               for x in ['train', 'val', 'test']}\n",
        "\n",
        "# Define the model\n",
        "model = models.resnet34(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Move the model to the GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# A function to train the model\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                # Track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(image_datasets[phase])\n",
        "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, criterion, optimizer, scheduler, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCRV9tbL1ljD",
        "outputId": "7e4bda3e-3e02-4e67-e248-dd870813dc3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 157MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.6068 Acc: 0.6594\n",
            "val Loss: 0.6330 Acc: 0.6910\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.2888 Acc: 0.8772\n",
            "val Loss: 0.4052 Acc: 0.8250\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.1271 Acc: 0.9514\n",
            "val Loss: 0.3702 Acc: 0.8635\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.0722 Acc: 0.9723\n",
            "val Loss: 0.3378 Acc: 0.8820\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.0582 Acc: 0.9784\n",
            "val Loss: 0.4662 Acc: 0.8545\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.0465 Acc: 0.9817\n",
            "val Loss: 0.3296 Acc: 0.8970\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.0349 Acc: 0.9881\n",
            "val Loss: 0.3059 Acc: 0.9095\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.0151 Acc: 0.9956\n",
            "val Loss: 0.1842 Acc: 0.9350\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.0078 Acc: 0.9980\n",
            "val Loss: 0.1816 Acc: 0.9345\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.0057 Acc: 0.9986\n",
            "val Loss: 0.1825 Acc: 0.9365\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.0060 Acc: 0.9984\n",
            "val Loss: 0.1796 Acc: 0.9370\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.0053 Acc: 0.9991\n",
            "val Loss: 0.1758 Acc: 0.9395\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.0037 Acc: 0.9993\n",
            "val Loss: 0.1727 Acc: 0.9420\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.0034 Acc: 0.9994\n",
            "val Loss: 0.1899 Acc: 0.9360\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.0030 Acc: 0.9994\n",
            "val Loss: 0.1731 Acc: 0.9385\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.0034 Acc: 0.9995\n",
            "val Loss: 0.1715 Acc: 0.9410\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.0033 Acc: 0.9993\n",
            "val Loss: 0.1702 Acc: 0.9425\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.0024 Acc: 0.9999\n",
            "val Loss: 0.1706 Acc: 0.9385\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.0036 Acc: 0.9991\n",
            "val Loss: 0.1700 Acc: 0.9435\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.0027 Acc: 0.9994\n",
            "val Loss: 0.1785 Acc: 0.9360\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0028 Acc: 0.9994\n",
            "val Loss: 0.1706 Acc: 0.9420\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.0033 Acc: 0.9992\n",
            "val Loss: 0.1731 Acc: 0.9410\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0035 Acc: 0.9991\n",
            "val Loss: 0.1734 Acc: 0.9420\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0029 Acc: 0.9996\n",
            "val Loss: 0.1694 Acc: 0.9430\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0025 Acc: 0.9996\n",
            "val Loss: 0.1760 Acc: 0.9360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test the model accuracy on the test set\n",
        "def test_model(model, dataloaders, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    running_corrects = 0\n",
        "\n",
        "    # No need to track gradients for testing\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['test']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Statistics\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    epoch_acc = running_corrects.double() / len(image_datasets['test'])\n",
        "    print(f'Test Acc: {epoch_acc:.4f}')\n",
        "\n",
        "# Test the model\n",
        "test_model(model, dataloaders, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAzBm7YO_HRe",
        "outputId": "62587691-d2b6-4ed9-f297-5b25cb7d5522"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 0.9260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), 'resnet34_model.pth')\n",
        "\n",
        "# Function to load the model\n",
        "def load_model(model_path):\n",
        "    # Make sure to provide the same number of classes as during training for the fully connected layer\n",
        "    model = models.resnet34(pretrained=False)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 2)  # Assuming we have 2 classes\n",
        "\n",
        "    # Load the saved state dictionary into the model\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "# Load the model\n",
        "model = load_model('resnet34_model.pth')\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, dataloaders, phases=['train', 'val', 'test']):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    results = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for phase in phases:\n",
        "            running_corrects = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                # Statistics\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "            results[phase] = epoch_acc.item()\n",
        "            print(f'{phase} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    return results\n",
        "\n",
        "# Evaluate the model\n",
        "results = evaluate_model(model, dataloaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djr0xwoWAB8d",
        "outputId": "388eaf5c-6212-4fdb-f593-8015969ed74f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Acc: 1.0000\n",
            "val Acc: 0.9360\n",
            "test Acc: 0.9260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow classification-models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AFW9_2nBwvU",
        "outputId": "8e3f0af2-a102-4366-8ade-854622ed0d97"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting classification-models\n",
            "  Downloading classification_models-0.1.tar.gz (3.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: classification-models\n",
            "  Building wheel for classification-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for classification-models: filename=classification_models-0.1-py3-none-any.whl size=4726 sha256=15e4efd1e26006091c85a5bcef33121b554033200970f4dd3cc9cd59c74fcd4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/f6/19/2e61ad3997efefe7079f3005074d68e103180974b16cb3f870\n",
            "Successfully built classification-models\n",
            "Installing collected packages: classification-models\n",
            "Successfully installed classification-models-0.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}